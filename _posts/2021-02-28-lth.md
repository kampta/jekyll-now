---
layout: project
title: The Lottery Ticket Hypothesis for Object Recognition
excerpt: How to find sparse neural networks (with up to 80% overall sparsity) on the tasks of object detection, segmentation, and pose estimation.   
code: https://github.com/Sharath-girish/LTH-ObjectRecognition
paper: https://openaccess.thecvf.com/content/CVPR2021/html/Girish_The_Lottery_Ticket_Hypothesis_for_Object_Recognition_CVPR_2021_paper.html
gif: lth_teaser.jpg
conference: CVPR 2021
---

  <div class="container">
  <nav_justify>
  <a href="https://sharath-girish.github.io/">Sharath Girish</a>
  <a href="https://scholar.google.com/citations?user=43zd4zIAAAAJ&hl=en">Shishira R Maiya</a>
  <a href="https://kampta.github.io/">Kamal Gupta</a>
  </nav_justify>
  </div>
  
  <div class="container" align="justify">
  <nav_justify>
  <a href="https://haochen-rye.github.io/">Hao Chen</a>
  <a href="http://users.umiacs.umd.edu/~lsd/">Larry Davis</a>
  <a href="">Abhinav Shrivastava</a>
  </nav_justify>
  </div>
  
  <div class="container" align="center">
  <p>University of Maryland, College Park</p>
  </div>
  
  <div class="container">
  <nav_justify>
  <a href="{{ page.code }}">[Code]</a>
  <a href="{{ page.paper }}">[arXiv]</a>
  <a href="https://www.youtube.com/watch?v=xunbBYpYWUs">[Video]</a>
  </nav_justify>
  </div>

  <br/>

  <div align="center">
  <img src="/images/{{ page.gif }}" alt="HTML5 Icon" style="float:left;margin-right:2em;margin-bottom:2em;">
  </div>
  
  <div align="center">
    <h1>Abstract</h1>
  </div>

  <div align="justify">
    Recognition tasks, such as object recognition and keypoint estimation, have seen widespread adoption in recent years. 
    Most state-of-the-art methods for these tasks use deep networks that are computationally expensive and have huge memory footprints. 
    This makes it exceedingly difficult to deploy these systems on low power embedded devices. 
    Hence, the importance of decreasing the storage requirements and the amount of computation in such models is paramount.
    The recently proposed Lottery Ticket Hypothesis (LTH) states that deep neural networks trained on large datasets 
    contain smaller subnetworks that achieve on par performance as the dense networks. 
    In this work, we perform the first empirical study investigating LTH for model pruning in the context of 
    object detection, instance segmentation, and keypoint estimation. 
    Our studies reveal that lottery tickets obtained from ImageNet pretraining do not transfer well to the downstream tasks. 
    We provide guidance on how to find lottery tickets with up to 80% overall sparsity on different sub-tasks 
    without incurring any drop in the performance. Finally, we analyse the behavior of trained tickets 
    with respect to various task attributes such as object size, frequency, and difficulty of detection.
  </div>

  
   <div align="center">
    <h1>Cite</h1>
  </div>
  
```
@InProceedings{Girish_2021_CVPR,
    author    = {Girish, Sharath and Maiya, Shishira R and Gupta, Kamal and Chen, Hao and Davis, Larry S. and Shrivastava, Abhinav},
    title     = {The Lottery Ticket Hypothesis for Object Recognition},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {762-771}
}
```
