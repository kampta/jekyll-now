---
layout: project
title: LayoutTransformer - Layout Generation and Completion with Self-attention
excerpt: A simple robust generative model for layouts; results on diverse real world datasets (3D objects, image, document layouts, mobile app wireframes)
code: https://github.com/kampta/DeepLayout
paper: https://arxiv.org/abs/2006.14615
gif: layout/layout_teasor.jpg
conference: ICCV 2021
authors: K. Gupta, A. Achille, J. Lazarow, L. Davis, V. Mahadevan, A. Shrivastava
---

  <div class="container">
  <nav_justify>
  <a href="https://kampta.github.io">Kamal Gupta<span class="sup">1</span></a>
  <a href="">Justin Lazarow<span class="sup">2</span></a>
  <a href="">Alessandro Achille<span class="sup">2</span></a>
  </nav_justify>
  </div>
  
  <div class="container" align="justify">
  <nav_justify>
  <a href="http://users.umiacs.umd.edu/~lsd/">Larry Davis<span class="sup">1,2</span></a>
  <a href="">Vijay Mahadevan<span class="sup">2</span></a>
  <a href="https://www.cs.umd.edu/~abhinav">Abhinav Shrivastava<span class="sup">1</span></a>
  </nav_justify>
  </div>
  
  <div class="container" align="center">
  <p><span class="sup">1</span>University of Maryland, College Park</p>
  <p><span class="sup">2</span>Amazon AWS</p>
  </div>
  
  <div class="container">
  <nav_justify>
  <a href="{{ page.code }}">[Code]</a>
  <a href="{{ page.paper }}">[arXiv]</a>
  <a href="https://www.youtube.com/watch?v=">[Video]</a>
  </nav_justify>
  </div>

  <br/>

  <img src="/images/{{ page.gif }}" alt="HTML5 Icon" style="float:left;margin-right:2em;margin-bottom:2em;">

  <div align="center">
    <h1>Abstract</h1>
  </div>

  <div align="justify">
    We address the problem of scene layout generation for diverse domains such as images, mobile applications, documents, and 3D objects.
    Most complex scenes, natural or human-designed, can be expressed as a meaningful arrangement of simpler compositional graphical primitives.
    Generating a new layout or extending an existing layout requires understanding the relationships between these primitives.
    To do this, we propose LayoutTransformer, a novel framework that leverages self-attention to learn contextual relationships between layout elements and generate novel layouts in a given domain.
    Our framework allows us to generate a new layout either from an empty set or from an initial seed set of primitives, and can easily scale to support an arbitrary of primitives per layout.
    Furthermore, our analyses show that the model is able to automatically capture the semantic properties of the primitives.
    We propose simple improvements in both representation of layout primitives, as well as training methods to demonstrate competitive performance in very diverse data domains such as object bounding boxes in natural images(COCO bounding box), documents (PubLayNet), mobile applications (RICO dataset) as well as 3D shapes (Part-Net).
  </div>

   <div align="center">
    <h1>Cite</h1>
  </div>
  
```
@inproceedings{gupta2020layout,
  title={LayoutTransformer: Layout Generation and Completion with Self-attention},
  author={Gupta, Kamal and Achille, Alessandro and Lazarow, Justin and Davis, Larry and Mahadevan, Vijay and Shrivastava, Abhinav},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2021}
}
```
